{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate autoregressive process and calculate correlations and t statistic for different sample sizes\n",
    "\n",
    "# Number of time iterations and different sample sizes\n",
    "times = 100\n",
    "ns = list(np.arange(50, 2000, 5))\n",
    "\n",
    "# Create combinations of time and sample size\n",
    "comb = pd.DataFrame(\n",
    "    [(ix, n) for ix in range(1, times + 1) for n in ns],\n",
    "    columns=['ix', 'n']\n",
    ")\n",
    "ncomb = len(comb)\n",
    "\n",
    "# Initialize result array and column names\n",
    "res = np.empty((ncomb, 5))\n",
    "res[:] = np.nan\n",
    "colnames = ['ix', 'n', 'cor', 'tstat', 'pval']\n",
    "\n",
    "# Simulate an autoregressive process\n",
    "def simulate_ar(n, phi):\n",
    "    ar_process = [0]\n",
    "    for _ in range(n):\n",
    "        ar_process.append(phi * ar_process[-1] + np.random.normal())\n",
    "    return ar_process[1:]\n",
    "\n",
    "# Iterate through combinations and calculate correlations and statistics\n",
    "for i in range(ncomb):\n",
    "    n = comb.loc[i, 'n']\n",
    "    ix = comb.loc[i, 'ix']\n",
    "    sim1 = simulate_ar(n, phi=1)\n",
    "    sim2 = simulate_ar(n, phi=1)\n",
    "    cor, pval = pearsonr(sim1, sim2)\n",
    "    tstat = cor * np.sqrt((n - 2) / (1 - cor**2))\n",
    "    res[i, :] = [ix, n, cor, tstat, pval]\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "tab = pd.DataFrame(res, columns=colnames)\n",
    "\n",
    "# Group the DataFrame by 'n' and calculate summary statistics\n",
    "tab_grouped = tab.groupby('n').agg(\n",
    "    avg_abs_corr=('cor', lambda x: np.mean(np.abs(x))),\n",
    "    avg_abs_tstat=('tstat', lambda x: np.mean(np.abs(x))),\n",
    "    percent_sig=('pval', lambda x: np.mean(x < 0.05))\n",
    ").reset_index()\n",
    "\n",
    "# Round values for cleaner presentation\n",
    "tab_grouped = tab_grouped.round(2)\n",
    "\n",
    "# Print the grouped and summarized results\n",
    "print(tab_grouped)\n",
    "plt.figure()\n",
    "plt.plot(tab_grouped['avg_abs_tstat'])\n",
    "plt.savefig(r'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Figures\\t_statistic_AR_process.pdf', format = 'pdf')\n",
    "plt.figure()\n",
    "plt.plot(tab_grouped['percent_sig'])\n",
    "plt.savefig(r'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Figures\\percent_significant_AR_process.pdf', format = 'pdf')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
